# Big Data - Interactive Advertising Analytics Project

## üéØ Cel projektu

Stworzenie systemu do analizy pogody, ruchu drogowego i sentymentu w Warszawie w celu wykorzystania w reklamamach. Projekt powinen umo≈ºliwiaƒá:

- Wykrywanie kork√≥w
- Analizƒô skuteczno≈õci pogody
- Analizƒô tweet√≥w pod kƒÖtem negatywnego sentymentu
- Ca≈Ço≈õciowe wykorzystanie analiz w celu wybrania miejsca i czasu na wy≈õwietlanie reklam

---

## üõ†Ô∏è Stos technologiczny

| Technologia      | Wersja | Zastosowanie                         | Port       |
| ---------------- | ------ | ------------------------------------ | ---------- |
| **Apache Kafka** | 7.4.0  | Buforowanie i streaming danych       | 9092       |
| **Kafka UI**     | latest | Interfejs do monitorowania Kafka     | 8090       |
| **Apache NiFi**  | latest | Pobieranie i preprocessing danych    | 8443       |
| **Apache Spark** | latest | Przetwarzanie danych i analityka     | 8080, 7077 |
| **Hadoop HDFS**  | latest | D≈Çugoterminowe przechowywanie danych | 9870, 9000 |
| **HBase**        | latest | Szybki dostƒôp do danych              | 16010      |
| **Zookeeper**    | 7.4.0  | Koordynacja us≈Çug rozproszonych      | 2181       |

---

## üì¶ Instalacja

### Wymagania systemowe

- **System operacyjny**: Windows 10/11 z WSL 2 (lub Linux/macOS)
- **RAM**: 16GB
- **Dysk**: ~10GB wolnego miejsca
- **Docker Desktop**: najnowsza wersja

### Instalacja na Windows

#### 1. Instalacja WSL 2

Otw√≥rz PowerShell jako **Administrator** i wykonaj:

```powershell
wsl --install
```

Po instalacji system poprosi o restart. Po restarcie:

- Ustaw login i has≈Ço dla WSL (nie bƒôdzie to potem potrzebne, ale proponujƒô jakie≈õ ≈Çatwe typu admin, password)

#### 2. Instalacja Docker Desktop

1. Pobierz Docker Desktop ze strony: https://www.docker.com/products/docker-desktop/
2. Uruchom instalator
3. **WA≈ªNE**: Podczas instalacji upewnij siƒô, ≈ºe zaznaczone jest:
   - ‚úÖ **Use WSL 2 based engine**
4. Po instalacji uruchom Docker Desktop
5. Poczekaj a≈º Docker siƒô w pe≈Çni uruchomi

#### 3. Uruchomienie projektu

Sklonuj repozytorium i przejd≈∫ do katalogu projektu:

```powershell
cd big-data-interactive-ads
```

Stw√≥rz ≈õrodowisko wirtualne i zaimportuj biblioteki python za pomocƒÖ uv:

```powershell
uv venv .venv
.venv\Scripts\activate
uv sync
```

Je≈õli nie posiadasz uv:

```powershell
pip install uv
```

Uruchom wszystkie us≈Çugi na docker:

```powershell
docker-compose up -d
```

#### 4. Weryfikacja instalacji

Poczekaj 2-3 minuty na uruchomienie wszystkich us≈Çug, nastƒôpnie sprawd≈∫ status:

```powershell
docker-compose ps
```

**Prawid≈Çowy wynik powinien wyglƒÖdaƒá tak:**

```
NAME           IMAGE                             STATUS
datanode       bde2020/hadoop-datanode:latest    Up
hbase          harisekhon/hbase:latest           Up
kafka          confluentinc/cp-kafka:7.4.0       Up
kafka-ui       provectuslabs/kafka-ui:latest     Up
namenode       bde2020/hadoop-namenode:latest    Up
nifi           apache/nifi:latest                Up
spark-master   apache/spark:latest               Up
spark-worker   apache/spark:latest               Up
zookeeper      confluentinc/cp-zookeeper:7.4.0   Up
```

Wszystkie kontenery powinny mieƒá status **"Up"**.

#### 5. Dostƒôp do interfejs√≥w webowych

Po uruchomieniu, sprawd≈∫ czy wszystkie interfejsy sƒÖ dostƒôpne:

| Us≈Çuga              | URL                         | Opis                                                       |
| ------------------- | --------------------------- | ---------------------------------------------------------- |
| **Kafka UI**        | http://localhost:8090       | Monitor Kafka topics i messages                            |
| **NiFi**            | https://localhost:8443/nifi | Przep≈Çywy danych (login: `admin` / has≈Ço: `adminadmin123`) |
| **Spark Master**    | http://localhost:8080       | Monitor Spark jobs                                         |
| **Hadoop NameNode** | http://localhost:9870       | HDFS filesystem                                            |
| **HBase Master**    | http://localhost:16010      | HBase tables                                               |

---

## ‚öôÔ∏è Uruchamianie wybranych us≈Çug

Ze wzglƒôdu na ograniczenia pamiƒôci RAM (16GB), mo≈ºesz uruchamiaƒá tylko wybrane us≈Çugi zamiast ca≈Çego stosu.

### Przyk≈Çad: Core Services (Kafka + Zookeeper)

Tylko podstawowe us≈Çugi do przesy≈Çania danych:

```powershell
docker-compose up -d zookeeper kafka kafka-ui
```

### Zatrzymywanie us≈Çug

Zatrzymaj wszystkie uruchomione us≈Çugi:

```powershell
docker-compose down
```

Zatrzymaj wybrane us≈Çugi (np. tylko NiFi):

```powershell
docker-compose stop nifi
```

### Sprawdzanie u≈ºycia zasob√≥w

Monitoruj u≈ºycie pamiƒôci RAM i CPU przez kontenery:

```powershell
docker stats --no-stream
```
