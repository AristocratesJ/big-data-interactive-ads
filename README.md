# Big Data - Interactive Advertising Analytics Project

## üéØ Cel projektu

Stworzenie systemu do analizy pogody, ruchu drogowego i sentymentu w Warszawie w celu wykorzystania w reklamamach. Projekt powinen umo≈ºliwiaƒá:

- Wykrywanie kork√≥w
- Analizƒô skuteczno≈õci pogody
- Analizƒô tweet√≥w pod kƒÖtem negatywnego sentymentu
- Ca≈Ço≈õciowe wykorzystanie analiz w celu wybrania miejsca i czasu na wy≈õwietlanie reklam

---

## üõ†Ô∏è Stos technologiczny

| Technologia      | Wersja | Zastosowanie                         | Port       |
| ---------------- | ------ | ------------------------------------ | ---------- |
| **Apache Kafka** | 7.4.0  | Buforowanie i streaming danych       | 9092       |
| **Kafka UI**     | latest | Interfejs do monitorowania Kafka     | 8090       |
| **Apache NiFi**  | latest | Pobieranie i preprocessing danych    | 8443       |
| **Apache Spark** | latest | Przetwarzanie danych i analityka     | 8080, 7077 |
| **Hadoop HDFS**  | latest | D≈Çugoterminowe przechowywanie danych | 9870, 9000 |
| **HBase**        | latest | Szybki dostƒôp do danych              | 16010      |
| **Zookeeper**    | 7.4.0  | Koordynacja us≈Çug rozproszonych      | 2181       |

---

## üì¶ Instalacja

### Wymagania systemowe

- **System operacyjny**: Windows 10/11 z WSL 2 (lub Linux/macOS)
- **RAM**: 16GB
- **Dysk**: ~10GB wolnego miejsca
- **Docker Desktop**: najnowsza wersja

### Instalacja na Windows

#### 1. Instalacja WSL 2

Otw√≥rz PowerShell jako **Administrator** i wykonaj:

```powershell
wsl --install
```

Po instalacji system poprosi o restart. Po restarcie:

- Ustaw login i has≈Ço dla WSL (nie bƒôdzie to potem potrzebne, ale proponujƒô jakie≈õ ≈Çatwe typu admin, password)

#### 2. Instalacja Docker Desktop

1. Pobierz Docker Desktop ze strony: https://www.docker.com/products/docker-desktop/
2. Uruchom instalator
3. **WA≈ªNE**: Podczas instalacji upewnij siƒô, ≈ºe zaznaczone jest:
   - ‚úÖ **Use WSL 2 based engine**
4. Po instalacji uruchom Docker Desktop
5. Poczekaj a≈º Docker siƒô w pe≈Çni uruchomi

#### 3. Uruchomienie projektu

Sklonuj repozytorium i przejd≈∫ do katalogu projektu:

```powershell
cd big-data-interactive-ads
```

Stw√≥rz ≈õrodowisko wirtualne i zaimportuj biblioteki python za pomocƒÖ uv:

```powershell
uv venv .venv
.venv\Scripts\activate
uv sync
```

Je≈õli nie posiadasz uv:

```powershell
pip install uv
```

Uruchom wszystkie us≈Çugi na docker:

```powershell
docker-compose up -d
```

#### 4. Weryfikacja instalacji

Poczekaj 2-3 minuty na uruchomienie wszystkich us≈Çug, nastƒôpnie sprawd≈∫ status:

```powershell
docker-compose ps
```

**Prawid≈Çowy wynik powinien wyglƒÖdaƒá tak:**

```
NAME           IMAGE                             STATUS
datanode       bde2020/hadoop-datanode:latest    Up
hbase          harisekhon/hbase:latest           Up
kafka          confluentinc/cp-kafka:7.4.0       Up
kafka-ui       provectuslabs/kafka-ui:latest     Up
namenode       bde2020/hadoop-namenode:latest    Up
nifi           apache/nifi:latest                Up
spark-master   apache/spark:latest               Up
spark-worker   apache/spark:latest               Up
zookeeper      confluentinc/cp-zookeeper:7.4.0   Up
```

Wszystkie kontenery powinny mieƒá status **"Up"**.

#### 5. Dostƒôp do interfejs√≥w webowych

Po uruchomieniu, sprawd≈∫ czy wszystkie interfejsy sƒÖ dostƒôpne:

| Us≈Çuga              | URL                         | Opis                                                       |
| ------------------- | --------------------------- | ---------------------------------------------------------- |
| **Kafka UI**        | http://localhost:8090       | Monitor Kafka topics i messages                            |
| **NiFi**            | https://localhost:8443/nifi | Przep≈Çywy danych (login: `admin` / has≈Ço: `adminadmin123`) |
| **Spark Master**    | http://localhost:8080       | Monitor Spark jobs                                         |
| **Hadoop NameNode** | http://localhost:9870       | HDFS filesystem                                            |
| **HBase Master**    | http://localhost:16010      | HBase tables                                               |

---

#### 6. Weryfikacja automatycznej konfiguracji

Po uruchomieniu `docker-compose up -d`, system **automatycznie** wykonuje pe≈ÇnƒÖ konfiguracjƒô:

- ‚úÖ Czeka na gotowo≈õƒá wszystkich us≈Çug (Kafka, HBase, NiFi)
- ‚úÖ Tworzy wszystkie tematy Kafka
- ‚úÖ Tworzy wszystkie tabele HBase
- ‚úÖ Wgrywa i instancjonuje szablon NiFi na canvas

Sprawd≈∫ logi automatycznej konfiguracji:

```powershell
docker-compose logs setup
```

Na ko≈Ñcu log√≥w powiniene≈õ zobaczyƒá:

```
‚úì SETUP COMPLETED SUCCESSFULLY!
```

Je≈õli zobaczysz b≈Çƒôdy, uruchom ponownie:

```powershell
docker-compose restart setup
docker-compose logs -f setup
```

#### 7. Uruchomienie przep≈Çyw√≥w danych

> **Wa≈ºne**: Po automatycznej konfiguracji z poprzedniego kroku, musisz rƒôcznie uruchomiƒá przep≈Çywy danych. Automatyczna konfiguracja tylko **przygotowuje** infrastrukturƒô (tematy, tabele, szablon), ale nie startuje pobierania i przetwarzania danych.

**7.1. Uruchom przep≈Çywy NiFi** (pobieranie danych z API):

```powershell
.\scripts\run_nifi_flows.ps1
```

To uruchomi wszystkie procesory NiFi, kt√≥re bƒôdƒÖ pobieraƒá dane z:

- ZTM API (autobusy i trolejbusy)
- Open-Meteo API (pogoda i jako≈õƒá powietrza)
- Twitter API (tweety z Warszawy)

**7.2. Uruchom zadania Spark** (przetwarzanie danych):

```powershell
.\scripts\run_spark_jobs.ps1
```

To uruchomi 4 zadania Spark, kt√≥re przetwarzajƒÖ dane z Kafka do HBase:

Teraz sprawd≈∫ czy zadania na Spark'u siƒô odpali≈Çy: http://localhost:8080

Poczekaj 30 sek. Powiniene≈õ zobaczyƒá **4 aktywne aplikacje** w sekcji "Running Applications":

1. `consume_buses_to_hbase`
2. `consume_trolleys_to_hbase`
3. `consume_weather_to_hbase`
4. `consume_air_quality_to_hbase`

Je≈õli nie zobaczysz wszystkich 4 zada≈Ñ, zrestartuj:

```powershell
.\scripts\stop_spark_jobs.ps1
.\scripts\run_spark_jobs.ps1
```

**Zatrzymywanie przep≈Çyw√≥w danych:**

```powershell
# Zatrzymaj NiFi procesory
.\scripts\stop_nifi_flows.ps1

# Zatrzymaj zadania Spark
.\scripts\stop_spark_jobs.ps1
```

#### 8. Weryfikacja dzia≈Çania systemu

Poczekaj 2-3 minuty na zebranie pierwszych danych, nastƒôpnie zweryfikuj:

**8.1. Sprawd≈∫ dane w HBase:**

```powershell
docker-compose exec hbase hbase shell
```

W HBase shell wykonaj:

```hbase
list
scan 'transport_events', {LIMIT => 1}
scan 'air_quality_forecast', {LIMIT => 1}
scan 'weather_forecast', {LIMIT => 1}
scan 'tweets', {LIMIT => 1}
exit
```

Je≈õli zobaczysz dane w tabelach - system dzia≈Ça poprawnie! ‚úÖ

**8.2. Monitoruj dane w Kafka UI:**

Otw√≥rz http://localhost:8090 i sprawd≈∫ tematy:

- `ztm-buses-raw` - powinny pojawiaƒá siƒô dane o autobusach
- `weather-forecast-raw` - dane pogodowe
- `air-quality-raw` - dane o jako≈õci powietrza
- `tweets-warsaw-raw` - tweety z Warszawy

---

## üîÑ Podsumowanie workflow

```
1. docker-compose up -d          ‚Üí Uruchamia wszystkie us≈Çugi + auto-konfiguracja
2. docker-compose logs setup     ‚Üí Sprawd≈∫ czy konfiguracja siƒô powiod≈Ça
3. .\scripts\run_nifi_flows.ps1  ‚Üí Uruchom pobieranie danych
4. .\scripts\run_spark_jobs.ps1  ‚Üí Uruchom przetwarzanie danych
5. Monitoruj w UI                ‚Üí Kafka UI, NiFi, Spark Master, HBase
```

**Ponowne uruchomienie po zatrzymaniu:**

```powershell
docker-compose down              # Zatrzymaj wszystko
docker-compose up -d             # Uruchom ponownie (auto-konfiguracja dzia≈Ça!)
.\scripts\run_nifi_flows.ps1    # Uruchom NiFi
.\scripts\run_spark_jobs.ps1    # Uruchom Spark
```

## ‚öôÔ∏è Uruchamianie wybranych us≈Çug

Ze wzglƒôdu na ograniczenia pamiƒôci RAM (16GB), mo≈ºesz uruchamiaƒá tylko wybrane us≈Çugi zamiast ca≈Çego stosu.

### Przyk≈Çad: Core Services (Kafka + Zookeeper)

Tylko podstawowe us≈Çugi do przesy≈Çania danych:

```powershell
docker-compose up -d zookeeper kafka kafka-ui
```

### Zatrzymywanie us≈Çug

Zatrzymaj wszystkie uruchomione us≈Çugi:

```powershell
docker-compose down
```

Zatrzymaj wybrane us≈Çugi (np. tylko NiFi):

```powershell
docker-compose stop nifi
```

### Sprawdzanie u≈ºycia zasob√≥w

Monitoruj u≈ºycie pamiƒôci RAM i CPU przez kontenery:

```powershell
docker stats --no-stream
```
