# Big Data - Interactive Advertising Analytics Project

## ğŸ¯ Cel projektu

Stworzenie systemu do analizy pogody, ruchu drogowego i sentymentu w Warszawie w celu wykorzystania w reklamamach. Projekt powinen umoÅ¼liwiaÄ‡:

- Wykrywanie korkÃ³w
- AnalizÄ™ skutecznoÅ›ci pogody
- AnalizÄ™ tweetÃ³w pod kÄ…tem negatywnego sentymentu
- **Decyzje Reklamowe (Ad Decision Engine)**: Automatyczne podejmowanie decyzji o wyÅ›wietleniu reklamy "na pocieszenie" (kampania eskapistyczna) w oparciu o zÅ‚Ä… pogodÄ™, korki i negatywne nastroje spoÅ‚eczne.

---

## ğŸ› ï¸ Stos technologiczny

| Technologia      | Wersja   | Zastosowanie                         | Port       |
| ---------------- | -------- | ------------------------------------ | ---------- |
| **Apache Kafka** | 7.4.0    | Buforowanie i streaming danych       | 9092       |
| **Kafka UI**     | latest   | Interfejs do monitorowania Kafka     | 8090       |
| **Apache NiFi**  | latest   | Pobieranie i preprocessing danych    | 8443       |
| **Apache Spark** | latest   | Przetwarzanie danych i analityka     | 8080, 7077 |
| **Hadoop HDFS**  | latest   | DÅ‚ugoterminowe przechowywanie danych | 9870, 9000 |
| **HBase**        | latest   | Szybki dostÄ™p do danych              | 16010      |
| **Apache Hive**  | Embedded | Hurtownia danych (via Spark)         | -          |
| **Zookeeper**    | 7.4.0    | Koordynacja usÅ‚ug rozproszonych      | 2181       |

---

## ï¿½ Konfiguracja Twitter API

Aby pobieraÄ‡ tweety z Warszawy, musisz skonfigurowaÄ‡ klucz API Twittera.

### 1. UtwÃ³rz plik `.env`

W gÅ‚Ã³wnym katalogu projektu utwÃ³rz plik `.env` z kluczem API:

```env
TWITTER_API_KEY=twÃ³j_klucz_api_tutaj
```

### 2. SkÄ…d wziÄ…Ä‡ klucz API?

Projekt uÅ¼ywa zewnÄ™trznego API Twitter (`api.twitterapi.io`). Aby uzyskaÄ‡ klucz:

1. Zarejestruj siÄ™ na platformie dostawcy API
2. Wygeneruj klucz API
3. Skopiuj klucz do pliku `.env`

### 3. Weryfikacja konfiguracji

Po uruchomieniu systemu, NiFi automatycznie uÅ¼yje klucza z pliku `.env` do uwierzytelniania Å¼Ä…daÅ„ do Twitter API.

MoÅ¼esz przetestowaÄ‡ poÅ‚Ä…czenie:

```powershell
python tests/twitter_api.py
```

> **Uwaga**: Bez prawidÅ‚owego klucza API, pobieranie tweetÃ³w nie bÄ™dzie dziaÅ‚aÄ‡, ale pozostaÅ‚e ÅºrÃ³dÅ‚a danych (ZTM, pogoda, jakoÅ›Ä‡ powietrza) bÄ™dÄ… funkcjonowaÄ‡ normalnie.

---

## ï¿½ğŸ“¦ Instalacja

### Wymagania systemowe

- **System operacyjny**: Windows 10/11 z WSL 2, Linux lub macOS
- **RAM**: 16GB
- **Dysk**: ~10GB wolnego miejsca
- **Docker Desktop**: najnowsza wersja

### Instalacja na Windows

#### 1. Instalacja WSL 2

OtwÃ³rz PowerShell jako **Administrator** i wykonaj:

```powershell
wsl --install
```

Po instalacji system poprosi o restart. Po restarcie:

- Ustaw login i hasÅ‚o dla WSL (nie bÄ™dzie to potem potrzebne, ale proponujÄ™ jakieÅ› Å‚atwe typu admin, password)

#### 2. Instalacja Docker Desktop

1. Pobierz Docker Desktop ze strony: https://www.docker.com/products/docker-desktop/
2. Uruchom instalator
3. **WAÅ»NE**: Podczas instalacji upewnij siÄ™, Å¼e zaznaczone jest:
   - âœ… **Use WSL 2 based engine**
4. Po instalacji uruchom Docker Desktop
5. Poczekaj aÅ¼ Docker siÄ™ w peÅ‚ni uruchomi

#### 3. Uruchomienie projektu

Sklonuj repozytorium i przejdÅº do katalogu projektu:

```powershell
cd big-data-interactive-ads
```

StwÃ³rz Å›rodowisko wirtualne i zaimportuj biblioteki python za pomocÄ… uv:

```powershell
uv venv .venv
.venv\Scripts\activate
uv sync
```

JeÅ›li nie posiadasz uv:

```powershell
pip install uv
```

Uruchom wszystkie usÅ‚ugi na docker:

```powershell
docker-compose up -d
```

#### 4. Weryfikacja instalacji

Poczekaj 2-3 minuty na uruchomienie wszystkich usÅ‚ug, nastÄ™pnie sprawdÅº status:

```powershell
docker-compose ps
```

**PrawidÅ‚owy wynik powinien wyglÄ…daÄ‡ tak:**

```
NAME           IMAGE                             STATUS
datanode       bde2020/hadoop-datanode:latest    Up
hbase          harisekhon/hbase:latest           Up
kafka          confluentinc/cp-kafka:7.4.0       Up
kafka-ui       provectuslabs/kafka-ui:latest     Up
namenode       bde2020/hadoop-namenode:latest    Up
nifi           apache/nifi:latest                Up
spark-master   apache/spark:latest               Up
spark-worker   apache/spark:latest               Up
zookeeper      confluentinc/cp-zookeeper:7.4.0   Up
```

Wszystkie kontenery powinny mieÄ‡ status **"Up"**.

#### 5. DostÄ™p do interfejsÃ³w webowych

Po uruchomieniu, sprawdÅº czy wszystkie interfejsy sÄ… dostÄ™pne:

| UsÅ‚uga              | URL                         | Opis                                                       |
| ------------------- | --------------------------- | ---------------------------------------------------------- |
| **Kafka UI**        | http://localhost:8090       | Monitor Kafka topics i messages                            |
| **NiFi**            | https://localhost:8443/nifi | PrzepÅ‚ywy danych (login: `admin` / hasÅ‚o: `adminadmin123`) |
| **Spark Master**    | http://localhost:8080       | Monitor Spark jobs                                         |
| **Hadoop NameNode** | http://localhost:9870       | HDFS filesystem                                            |
| **HBase Master**    | http://localhost:16010      | HBase tables                                               |

---

#### 6. Weryfikacja automatycznej konfiguracji

Po uruchomieniu `docker-compose up -d`, system **automatycznie** wykonuje peÅ‚nÄ… konfiguracjÄ™:

- âœ… Czeka na gotowoÅ›Ä‡ wszystkich usÅ‚ug (Kafka, HBase, NiFi)
- âœ… Tworzy wszystkie tematy Kafka
- âœ… Tworzy wszystkie tabele HBase
- âœ… Wgrywa i instancjonuje szablon NiFi na canvas

SprawdÅº logi automatycznej konfiguracji:

```powershell
docker-compose logs setup
```

Na koÅ„cu logÃ³w powinieneÅ› zobaczyÄ‡:

```
âœ“ SETUP COMPLETED SUCCESSFULLY!
```

JeÅ›li zobaczysz bÅ‚Ä™dy, uruchom ponownie:

```powershell
docker-compose restart setup
docker-compose logs -f setup
```

#### 7. Uruchomienie przepÅ‚ywÃ³w danych

> **WaÅ¼ne**: Po automatycznej konfiguracji z poprzedniego kroku, musisz rÄ™cznie uruchomiÄ‡ przepÅ‚ywy danych. Automatyczna konfiguracja tylko **przygotowuje** infrastrukturÄ™ (tematy, tabele, szablon), ale nie startuje pobierania i przetwarzania danych.

**7.1. Uruchom przepÅ‚ywy NiFi** (pobieranie danych z API):

#### macOS / Linux

```bash
./scripts/run_nifi_flows.sh
```

#### Windows (PowerShell)

```powershell
.\scripts\run_nifi_flows.ps1
```

To uruchomi wszystkie procesory NiFi, ktÃ³re bÄ™dÄ… pobieraÄ‡ dane z:

- ZTM API (autobusy i trolejbusy)
- Open-Meteo API (pogoda i jakoÅ›Ä‡ powietrza)
- Twitter API (tweety z Warszawy)

**7.2. Uruchom zadania Spark** (przetwarzanie danych):

#### macOS / Linux

```bash
./scripts/run_spark_jobs.sh
```

#### Windows (PowerShell)

```powershell
.\scripts\run_spark_jobs.ps1
```

To uruchomi:

1. **5 zadaÅ„ Spark Streaming** (przetwarzanie danych z Kafka do HBase):
   - Buses
   - Trolleys
   - Weather
   - Air Quality
   - Twitter Sentiment
2. **Ad Campaign Manager** (niezaleÅ¼ny proces Python podejmujÄ…cy decyzje)
3. **Hive Archiver Scheduler** (automatyczny proces w tle)

Teraz sprawdÅº czy zadania na Spark'u siÄ™ odpaliÅ‚y: http://localhost:8080

Poczekaj 30 sek. PowinieneÅ› zobaczyÄ‡ **5 aktywnych aplikacji streamingowych** w sekcji "Running Applications".

> **Uwaga**: `ad_campaign_manager.py` oraz `archive_to_hive.py` (scheduler) dziaÅ‚ajÄ… jako procesy w tle i nie zawsze sÄ… widoczne na gÅ‚Ã³wnej liÅ›cie aplikacji streamingowych w Spark UI (chyba Å¼e w momencie wykonywania batcha).

JeÅ›li nie zobaczysz zadaÅ„, zrestartuj:

#### macOS / Linux

```bash
./scripts/stop_spark_jobs.sh
./scripts/run_spark_jobs.sh
```

#### Windows (PowerShell)

```powershell
.\scripts\stop_spark_jobs.ps1
.\scripts\run_spark_jobs.ps1
```

**Zatrzymywanie przepÅ‚ywÃ³w danych:**

#### macOS / Linux

```bash
# Zatrzymaj NiFi procesory
./scripts/stop_nifi_flows.sh

# Zatrzymaj zadania Spark + Ad Manager
./scripts/stop_spark_jobs.sh
```

#### Windows (PowerShell)

```powershell
# Zatrzymaj NiFi procesory
.\scripts\stop_nifi_flows.ps1

# Zatrzymaj zadania Spark + Ad Manager
.\scripts\stop_spark_jobs.ps1
```

#### 8. Weryfikacja dziaÅ‚ania systemu

Poczekaj 2-3 minuty na zebranie pierwszych danych, nastÄ™pnie zweryfikuj:

**8.1. SprawdÅº dane w HBase:**

```powershell
docker-compose exec hbase hbase shell
```

W HBase shell wykonaj:

```hbase
list
scan 'transport_events', {LIMIT => 1}
scan 'air_quality_forecast', {LIMIT => 1}
scan 'weather_forecast', {LIMIT => 1}
scan 'tweets', {LIMIT => 1}
scan 'ad_decisions', {LIMIT => 1}
exit
```

JeÅ›li zobaczysz dane w tabelach - system dziaÅ‚a poprawnie! âœ…

**8.2. Monitoruj dane w Kafka UI:**

OtwÃ³rz http://localhost:8090 i sprawdÅº tematy:

- `ztm-buses-raw` - powinny pojawiaÄ‡ siÄ™ dane o autobusach
- `weather-forecast-raw` - dane pogodowe
- `air-quality-raw` - dane o jakoÅ›ci powietrza
- `tweets-warsaw-raw` - tweety z Warszawy
- `ad-decisions` - wyniki decyzji reklamowych

---

## Analityka i Archiwizacja (Hive)

System posiada dedykowanÄ… warstwÄ™ analitycznÄ… opartÄ… o **Apache Hive** (wbudowany w Spark), ktÃ³ra archiwizuje decyzje reklamowe na HDFS w formacie Parquet.

### 1. Architektura

- **Decyzje (Real-time)**: `ad_campaign_manager.py` wysyÅ‚a decyzje do **Kafka** (`ad-decisions`) i **HBase**.
- **Archiwizacja (Batch)**: Job `archive_to_hive.py` uruchamiany okresowo przenosi dane z HBase do **Hive** (`ad_decisions_archive`) na HDFS.

### 2. Monitorowanie Archiwizacji

Job archiwizacyjny dziaÅ‚a automatycznie w tle. MoÅ¼esz sprawdziÄ‡ jego status przeglÄ…dajÄ…c logi w kontenerze:

#### macOS / Linux / Windows

```bash
docker exec spark-master tail -f /opt/spark-apps/archive.log
```

### 3. Weryfikacja Danych w Hive

MoÅ¼esz sprawdziÄ‡ zarchiwizowane dane za pomocÄ… przygotowanego skryptu:

#### macOS / Linux

```bash
docker exec -u root spark-master /opt/spark/bin/spark-submit /opt/spark-apps/check_hive_data.py
```

#### Windows (PowerShell)

```powershell
docker exec -u root spark-master /opt/spark/bin/spark-submit /opt/spark-apps/check_hive_data.py
```

MoÅ¼esz rÃ³wnieÅ¼ przeglÄ…daÄ‡ pliki fizycznie na HDFS przez przeglÄ…darkÄ™: http://localhost:9870/explorer.html#/user/hive/warehouse/ad_decisions_archive

## ğŸ”„ Podsumowanie workflow

```
1. docker-compose up -d          â†’ Uruchamia wszystkie usÅ‚ugi + auto-konfiguracja
2. docker-compose logs setup     â†’ SprawdÅº czy konfiguracja siÄ™ powiodÅ‚a
3. .\scripts\run_nifi_flows.ps1  â†’ Uruchom pobieranie danych
4. .\scripts\run_spark_jobs.ps1  â†’ Uruchom przetwarzanie danych
5. Monitoruj w UI                â†’ Kafka UI, NiFi, Spark Master, HBase
```

**Ponowne uruchomienie po zatrzymaniu:**

#### macOS / Linux

```bash
docker-compose down              # Zatrzymaj wszystko
docker-compose up -d             # Uruchom ponownie
./scripts/run_nifi_flows.sh      # Uruchom NiFi
./scripts/run_spark_jobs.sh      # Uruchom Spark
```

#### Windows (PowerShell)

```powershell
docker-compose down              # Zatrzymaj wszystko
docker-compose up -d             # Uruchom ponownie
.\scripts\run_nifi_flows.ps1     # Uruchom NiFi
.\scripts\run_spark_jobs.ps1     # Uruchom Spark
```

## âš™ï¸ Uruchamianie wybranych usÅ‚ug

Ze wzglÄ™du na ograniczenia pamiÄ™ci RAM (16GB), moÅ¼esz uruchamiaÄ‡ tylko wybrane usÅ‚ugi zamiast caÅ‚ego stosu.

### PrzykÅ‚ad: Core Services (Kafka + Zookeeper)

Tylko podstawowe usÅ‚ugi do przesyÅ‚ania danych:

```powershell
docker-compose up -d zookeeper kafka kafka-ui
```

### Zatrzymywanie usÅ‚ug

Zatrzymaj wszystkie uruchomione usÅ‚ugi:

```powershell
docker-compose down
```

Zatrzymaj wybrane usÅ‚ugi (np. tylko NiFi):

```powershell
docker-compose stop nifi
```

### Sprawdzanie uÅ¼ycia zasobÃ³w

Monitoruj uÅ¼ycie pamiÄ™ci RAM i CPU przez kontenery:

```powershell
docker stats --no-stream
```
